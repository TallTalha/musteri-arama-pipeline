MÃ¼ÅŸteri Arama KayÄ±tlarÄ± - Veri MÃ¼hendisliÄŸi Boru HattÄ± Projesi ğŸš€

Bu proje, modern veri mÃ¼hendisliÄŸi araÃ§larÄ±nÄ± kullanarak bir e-ticaret platformundaki kullanÄ±cÄ± arama olaylarÄ±nÄ± yakalayan, iÅŸleyen ve analiz eden uÃ§tan uca bir veri boru hattÄ±dÄ±r.

1. Projenin AmacÄ±

Bu projenin temel amacÄ±, bir e-ticaret platformunda kullanÄ±cÄ±larÄ±n yaptÄ±ÄŸÄ± arama sorgularÄ±nÄ± anlÄ±k (real-time) ve toplu (batch) olarak analiz etmektir. Toplanan verilerle, aÅŸaÄŸÄ±daki gibi iÅŸ sorularÄ±na veri odaklÄ± cevaplar aranÄ±r:

    Hangi Ã¼rÃ¼nler anlÄ±k olarak trend oluyor?

    GÃ¼nÃ¼n hangi saatlerinde arama yoÄŸunluÄŸu artÄ±yor?

    Hangi kullanÄ±cÄ± hangi Ã¼rÃ¼nlerle daha Ã§ok ilgileniyor?

    KullanÄ±cÄ± davranÄ±ÅŸlarÄ±na gÃ¶re kiÅŸiselleÅŸtirilmiÅŸ deneyimler nasÄ±l sunulur?

Bu proje, bu sorularÄ± cevaplamak iÃ§in gerekli olan veri altyapÄ±sÄ±nÄ± kurma ve iÅŸletme sÃ¼reÃ§lerini kapsar.

2. Mimari ve Veri AkÄ±ÅŸÄ±

Proje, endÃ¼stri standardÄ± olan, ayrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ (decoupled) ve Ã¶lÃ§eklenebilir bir mimari Ã¼zerine kurulmuÅŸtur. Veri akÄ±ÅŸÄ± aÅŸaÄŸÄ±daki gibidir:

![A flowchart diagram showing the architecture of a customer search data pipeline. The diagram includes labeled components: Front-end Search Box JSON Data, Back-end FAST API Producer, Apache Kafka topic search-logs Listener, Apache Spark Spark Job Batch Process, Apache Spark Stream Instant Data Analysis, and MongoDB NoSQL. Arrows indicate the flow of data between these components. The environment is technical and structured, with a neutral and informative tone. Additional labels include Digital Ocean Droplet and MÃ¼ÅŸteri Arama Pipeline at the top.](images/flow.svg)

    Veri Ãœretimi (data_generator.py / API): KullanÄ±cÄ± arama olaylarÄ±, gerÃ§ekÃ§i bir daÄŸÄ±lÄ±m ve zaman serisiyle simÃ¼le edilir. Her arama, bir JSON mesajÄ± olarak oluÅŸturulur.

    Veri TaÅŸÄ±ma (Apache Kafka): Ãœretilen bu JSON mesajlarÄ±, yÃ¼ksek hacimli veri akÄ±ÅŸÄ±nÄ± kayÄ±psÄ±z ve gecikmesiz bir ÅŸekilde yÃ¶netebilen Kafka'daki topic'lere gÃ¶nderilir (produce).

    Veri Ä°ÅŸleme (Apache Spark):

        Batch Ä°ÅŸleme: Periyodik olarak Ã§alÄ±ÅŸan Spark iÅŸleri, Kafka'da birikmiÅŸ verileri toplu olarak okur, Ã¼zerinde agregasyon ve pivot gibi karmaÅŸÄ±k analizler yapar. (Ã–rn: pivot_analysis.py)

        Streaming Ä°ÅŸleme: SÃ¼rekli Ã§alÄ±ÅŸan Spark iÅŸleri, Kafka'ya veri geldiÄŸi anda onu yakalar, anlÄ±k filtreleme ve basit dÃ¶nÃ¼ÅŸÃ¼mler yapar. (Ã–rn: streaming_consumer.py)

    Veri Depolama (MongoDB): Spark tarafÄ±ndan iÅŸlenip anlamlÄ± hale getirilen analiz sonuÃ§larÄ± (Ã¶rn: pivot tablolar, trend raporlarÄ±), daha sonra dashboard'larda kullanÄ±lmak veya baÅŸka servisler tarafÄ±ndan okunmak Ã¼zere MongoDB'ye yazÄ±lÄ±r.

3. KullanÄ±lan Teknolojiler

    Veri AkÄ±ÅŸÄ± ve MesajlaÅŸma: Apache Kafka

    Veri Ä°ÅŸleme: Apache Spark 3.5.1 (PySpark)

    Veri Depolama: MongoDB

    API Servisi: Python, FastAPI, Uvicorn

    Veri Ãœretimi (SimÃ¼lasyon): Python, Faker, kafka-python

    AltyapÄ±: DigitalOcean Ubuntu Sunucu 24.04

    GÃ¶zlemlenebilirlik (Logging): Python logging modÃ¼lÃ¼

    ArayÃ¼z ve YÃ¶netim: MongoDB Compass

    Versiyon KontrolÃ¼: Git & GitHub

4. Proje YapÄ±sÄ±

Proje, her birinin kendi sorumluluÄŸu ve sanal ortamÄ± olan modÃ¼ler bir yapÄ±da organize edilmiÅŸtir:
```
musteri-arama-pipeline/
â”œâ”€â”€ api/                  # FastAPI uygulamasÄ± ve baÄŸÄ±mlÄ±lÄ±klarÄ±
â”‚   â”œâ”€â”€ venv-api/
â”‚   â””â”€â”€ main.py           # Backend API simÃ¼lasyonudur, FastAPI kullanÄ±lÄ±r.         
â”œâ”€â”€ data-generator/       # Test verisi Ã¼retici script'i
â”‚   â”œâ”€â”€ venv-gen/
â”‚   â””â”€â”€ data_generator.py # user_id,search-term,region, timestamp gibi bilgileri rastgele Ã¼retir
â”œâ”€â”€ spark-consumer/       # Spark iÅŸleri (batch ve streaming)
â”‚   â”œâ”€â”€ venv-spark/
â”‚   â”œâ”€â”€ batch_consumer.py # search-logs topiÄŸindeki verileri Ã§eker ve mongodb'ye yazar
â”‚   â”œâ”€â”€ pivot_analysis.py # user_id bazÄ±nda pivot iÅŸlemleri yapar ve mongodb'ye yazar
â”‚   â”œâ”€â”€ realtime_tracker.py # anlÄ±k verileri kafkadan Ã§eker sonra filtreler ve mongodb'ye yazar
â”‚   â”œâ”€â”€ streaming_consumer.py # anlÄ±k verileri kafkadan Ã§eker ve mongodb'ye yazar
â”‚   â””â”€â”€ trending_topic_analysis.py # gÃ¼nlÃ¼k verileri 30 dakikalÄ±k dilimlere bÃ¶ler ve mongodb'ye yazar
â”œ   
â”œâ”€â”€ utils/                # YardÄ±mcÄ± modÃ¼ller (Ã¶rn: merkezi logger)
â”‚   â””â”€â”€ logger.py         #Logging modÃ¼lÃ¼dÃ¼r, logging kÃ¼tÃ¼phanesi kullanÄ±lÄ±r
â”œâ”€â”€ logs/                 # Log dosyalarÄ±nÄ±n tutulduÄŸu klasÃ¶r (git'e dahil deÄŸil)
â”œâ”€â”€ checkpoint/           # Spark Streaming checkpoint'leri (git'e dahil deÄŸil)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
5. Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

Bu projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in sunucu tarafÄ±nda ve yerel tarafta belirli adÄ±mlarÄ±n izlenmesi gerekir.

Ã–n Gereksinimler

    Sunucuda Java, Python3, venv ve git kurulu olmalÄ±dÄ±r.

    Sunucuda Apache Kafka, Apache Spark, MongoDB ve Elasticsearch/Kibana servisleri Ã§alÄ±ÅŸÄ±r durumda olmalÄ±dÄ±r.

Ã‡alÄ±ÅŸtÄ±rma AdÄ±mlarÄ±

    Kod Senkronizasyonu:

        Yerel PC: git clone https://github.com/TallTalha/musteri-arama-pipeline.git

        Sunucu: AynÄ± git clone komutu ile projeyi sunucuya da klonlayÄ±n. GeliÅŸtirme dÃ¶ngÃ¼sÃ¼nde git pull ile gÃ¼ncelleyin.

    BaÄŸÄ±mlÄ±lÄ±klarÄ±n Kurulumu: Projedeki her alt klasÃ¶r (api, data-generator, spark-consumer) iÃ§in kendi venv'ini oluÅŸturun ve pip install -r requirements.txt ile baÄŸÄ±mlÄ±lÄ±klarÄ± kurun. (Not: HenÃ¼z requirements.txt dosyalarÄ± oluÅŸturmadÄ±k, bu bir sonraki best practice adÄ±mÄ± olabilir!)

    Veri Boru HattÄ±nÄ± Ã‡alÄ±ÅŸtÄ±rma:

        [KENDÄ° PC'NDE - Terminal 1]: Uzak sunucudaki servislere eriÅŸim iÃ§in SSH tÃ¼nelini baÅŸlat: ssh sunucum

        [SUNUCUDA - Terminal 2]: Veriyi anlÄ±k olarak iÅŸleyecek olan Spark Streaming iÅŸini baÅŸlat: sudo spark-submit ... spark-consumer/streaming_consumer.py

        [KENDÄ° PC'NDE - Terminal 3]: Veri Ã¼retecek olan API servisini baÅŸlat: uvicorn api.main:app ...

        [TarayÄ±cÄ±/Postman]: API'ye (http://localhost:8080/search/stream) istekler gÃ¶ndererek tÃ¼m hattÄ± uÃ§tan uca test et.


